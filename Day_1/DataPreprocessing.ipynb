{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typical Data Preparation steps\n",
    "\n",
    " - Getting the necessary python libraries \n",
    " - Loading the dataset \n",
    " - Dealing with **Missing values** & **Categorical features** \n",
    " - Splitting the data into **Training sets** & **Testing sets**\n",
    " - Normalization of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the necessary python libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('loans.csv') #Store the dataset in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     City   Age   Revenue Approved\n",
      "0  Medina  25.0   65000.0      Yes\n",
      "1   Mecca  30.0   81000.0       No\n",
      "2  Riyadh  33.0       NaN      Yes\n",
      "3  Medina  39.0  100000.0       No\n",
      "4   Mecca  28.0   91000.0      Yes\n",
      "5  Riyadh   NaN   66000.0       No\n",
      "6  Medina  40.0   98000.0      Yes\n",
      "7   Mecca  34.0   86000.0      Yes\n",
      "8  Riyadh  25.0   70000.0       No\n",
      "9   Mecca  24.0   62000.0      Yes\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [:, :-1] Store all the raws, Store all the columns except the last one\n",
    "X = dataset.iloc[:,:-1].values\n",
    "\n",
    "# [:,3] Store all the raws,  Store colum 3 (Target Co)\n",
    "y = dataset.iloc[:,3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Medina' 25.0 65000.0]\n",
      " ['Mecca' 30.0 81000.0]\n",
      " ['Riyadh' 33.0 nan]\n",
      " ['Medina' 39.0 100000.0]\n",
      " ['Mecca' 28.0 91000.0]\n",
      " ['Riyadh' nan 66000.0]\n",
      " ['Medina' 40.0 98000.0]\n",
      " ['Mecca' 34.0 86000.0]\n",
      " ['Riyadh' 25.0 70000.0]\n",
      " ['Mecca' 24.0 62000.0]]\n",
      "\n",
      "['Yes' 'No' 'Yes' 'No' 'Yes' 'No' 'Yes' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "print (X)\n",
    "print ()\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values\n",
    "\n",
    "Rows with missing values can be easily dropped via the dropna method >>> df.dropna(axis=0)\n",
    "\n",
    "Similarly, we can drop columns that have at least one NaN in any row by setting the axis argument to 1 >>> df.dropna(axis=1)\n",
    "\n",
    "Only drop rows where all columns are NaN >>> df.dropna(how='allâ€™)\n",
    "\n",
    "Keep only the rows with at least 2 non-NaN values. >>> df.dropna(thresh=2)\n",
    "\n",
    "Only drop rows where NaN appear in specific columns (here: 'C') >>> df.dropna(subset=['C'])\n",
    "\n",
    "Note: df is the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "              missing_values=nan, strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit(X[:,[1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,1:3]= imputer.transform(X[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Medina' 25.0 65000.0]\n",
      " ['Mecca' 30.0 81000.0]\n",
      " ['Riyadh' 33.0 79888.88888888889]\n",
      " ['Medina' 39.0 100000.0]\n",
      " ['Mecca' 28.0 91000.0]\n",
      " ['Riyadh' 30.88888888888889 66000.0]\n",
      " ['Medina' 40.0 98000.0]\n",
      " ['Mecca' 34.0 86000.0]\n",
      " ['Riyadh' 25.0 70000.0]\n",
      " ['Mecca' 24.0 62000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X = LabelEncoder() #encode categorical features in X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:,0] = labelencoder_X.fit_transform(X[:,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 25.0 65000.0]\n",
      " [0 30.0 81000.0]\n",
      " [2 33.0 79888.88888888889]\n",
      " [1 39.0 100000.0]\n",
      " [0 28.0 91000.0]\n",
      " [2 30.88888888888889 66000.0]\n",
      " [1 40.0 98000.0]\n",
      " [0 34.0 86000.0]\n",
      " [2 25.0 70000.0]\n",
      " [0 24.0 62000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features=[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X = onehotencoder.fit_transform(X).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 1.00000000e+00 0.00000000e+00 2.50000000e+01\n",
      "  6.50000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.00000000e+01\n",
      "  8.10000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.30000000e+01\n",
      "  7.98888889e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 3.90000000e+01\n",
      "  1.00000000e+05]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 2.80000000e+01\n",
      "  9.10000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 3.08888889e+01\n",
      "  6.60000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 0.00000000e+00 4.00000000e+01\n",
      "  9.80000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 3.40000000e+01\n",
      "  8.60000000e+04]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00 2.50000000e+01\n",
      "  7.00000000e+04]\n",
      " [1.00000000e+00 0.00000000e+00 0.00000000e+00 2.40000000e+01\n",
      "  6.20000000e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_y = LabelEncoder() #encode categorical features in y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2) \n",
    "#Test size = 20%, training size = 80% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc_X.fit_transform(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
